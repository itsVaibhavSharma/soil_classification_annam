{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG2h-3cWah1W"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "inference.ipynb\n",
        "\n",
        "Title: Soil Type Classification - Inference Notebook\n",
        "Team: Team Cygnus\n",
        "Authors: Vaibhav Sharma, Shreya Khantal, Prasanna Saxena\n",
        "Model: ResNet50\n",
        "Best Model: 'best_resnet50.pth'\n",
        "\n",
        "'''\n",
        "# --- Step 1: Import Libraries ---\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Step 2: Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# Class mapping\n",
        "class_names = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
        "inv_label_mapping = {i: name for i, name in enumerate(class_names)}\n",
        "\n",
        "# --- Step 3: Define Dataset Class ---\n",
        "class SoilDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx]['image_id']\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# --- Step 4: Define Transform (Replace with actual values if known) ---\n",
        "mean = [0.51927466, 0.41479487, 0.32805257]\n",
        "std = [0.27258596, 0.25516909, 0.22726975]\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# --- Step 4: Preprocessing through Resizing & Augmentation \n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "\n",
        "# --- Step 5: Load Test Data ---\n",
        "DATA_DIR = \"/kaggle/input/soil-classification/soil_classification-2025\"\n",
        "TEST_IMG_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test_ids.csv\"))\n",
        "\n",
        "# Ensure file extension\n",
        "if not test_df['image_id'].iloc[0].endswith('.jpg'):\n",
        "    test_df['image_id'] = test_df['image_id'].apply(lambda x: x + '.jpg')\n",
        "\n",
        "test_dataset = SoilDataset(test_df, TEST_IMG_DIR, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# --- Step 6: Load Trained Model ---\n",
        "def create_model(num_classes):\n",
        "    model = models.resnet50(weights=None)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = torch.nn.Sequential(\n",
        "        torch.nn.Dropout(0.3),\n",
        "        torch.nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES)\n",
        "model.load_state_dict(torch.load('best_resnet50.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- Step 7: Inference ---\n",
        "def predict(model, dataloader):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm(dataloader, desc=\"Predicting\"):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "    return predictions\n",
        "\n",
        "test_preds = predict(model, test_loader)\n",
        "test_labels = [inv_label_mapping[pred] for pred in test_preds]\n",
        "\n",
        "# --- Step 8: Create Submission ---\n",
        "submission_df = pd.DataFrame({\n",
        "    'image_id': test_df['image_id'],\n",
        "    'soil_type': test_labels\n",
        "})\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission saved to submission.csv\")\n",
        "submission_df.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
